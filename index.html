<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Project page for NeurIPS paper Localizing Memorization in SSL Vision Encoders">
  <meta property="og:title" content="Localizing SSLMem"/>
  <meta property="og:description" content="Localizing Memorization in SSL Vision Encoders (NeurIPS 2024)"/>
  <meta property="og:url" content="https://wenhaowang1995.github.io/SSLMem_localization/"/>

  
  <meta name="keywords" content="self-supervised learning, memorization, localization">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Localizing Memorization in SSL Vision Encoders</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Localizing Memorization in SSL Vision Encoders</h1>
            <img src="static/images/NeurIPS-logo.svg" alt="NeurIPS" style="width:40%;"/>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://wenhaowang1995.github.io/" target="_blank">Wenhao Wang</a>,</span>
                <span class="author-block">
                  <a href="https://adam-dziedzic.com/" target="_blank">Adam Dziedzic</a>,</span>
                  <span class="author-block">
                    <a href="https://michaelbackes.eu/" target="_blank">Michael Backes</a>,</span>
                    <span class="author-block">
                      <a href="https://franziska-boenisch.de/" target="_blank">Franziska Boenisch</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">CISPA Helmholtz Center for Information Security<br></span>
          
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2409.19069" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/sprintml/LocalizingMemorizationInSSL" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2409.19069>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Paper Key Takeaways -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        
          <p>
            <b>Poster Location：</b> East Exhibit Hall A-C #3411, Fri 13 Dec 4:30 p.m. — 7:30 p.m. PST
          </p>
       
    </div>
  </div>
</section>
<!-- End paper Key Takeaways -->

  

  <!-- Teaser video-->
<section class="section hero is-light">
  <div class="container is-max-desktop">           
      <h2 class="subtitle has-text-centered">
        <b>TL;DR:</b> We define 2 novel metric, LayerMem and UnitMem, to identify where the memorization happens in self-supervised learning encoders.      
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent work on studying memorization in self-supervised learning (SSL) suggests that even though SSL encoders are trained on millions of images, they still memorize individual data points. While effort has been put into characterizing the memorized data and linking encoder memorization to downstream utility, little is known about where the memorization happens inside SSL encoders. To close this gap, we propose two metrics for localizing memorization in SSL encoders on a per-layer (LayerMem) and per-unit basis (UnitMem). Our localization methods are independent of the downstream task, do not require any label information, and can be performed in a forward pass. By localizing memorization in various encoder architectures (convolutional and transformer-based) trained on diverse datasets with contrastive and non-contrastive SSL frameworks, we find that (1) while SSL memorization increases with layer depth, highly memorizing units are distributed across the entire encoder, (2) a significant fraction of units in SSL encoders experiences surprisingly high memorization of individual data points, which is in contrast to models trained under supervision, (3) atypical (or outlier) data points cause much higher layer and unit memorization than standard data points, and (4) in vision transformers, most memorization happens in the fully-connected layers. Finally, we show that localizing memorization in SSL has the potential to improve f ine-tuning and to inform pruning strategies.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Paper Key Takeaways -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
        <div class="content has-text-justified">
          <h2 class="title is-3">Main Contributions</h2>
          <ol>
            <li><b>LayerMem</b> A novel per-layer metric to evaluate the memorization for SSL encoders</li>
            <li><b>UnitMem</b> A novel per-unit (neuron) metric to evaluate the memorization for SSL encoders</li>
            <li><b>Pratical Benefits</b> for encoder fine-tuning and pruning by using LayerMem and UnitMem</li>
          </ol> 
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Key Takeaways -->











<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/Poster__ICML_2024_locate_Memorization.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
@inproceedings{
wang2024localizing,
title={Localizing Memorization in {SSL} Vision Encoders},
author={Wenhao Wang and Adam Dziedzic and Michael Backes and Franziska Boenisch},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
url={https://openreview.net/forum?id=R46HGlIjcG}
}
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
